# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wH67vs_PjQxKw7ajw8JJzYkqFEqS7JK5
"""

import pandas as pd
from nltk.stem.porter import PorterStemmer

import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

df=pd.read_csv('/content/drive/MyDrive/Document from Abhinlp',delimiter='\t',quoting=3)

df.head()

df.shape

df["Review"][0]

df.info()

df.columns

import re

import string
import re
corpus=[]
for i in range(0,1000):
  # Replace 'rep1' with 'repl' for the replacement string argument
  review=re.sub(pattern='[^a-zA-Z]',repl=' ',string=df['Review'][i])
  review=review.lower()
  review_word=review.split()
  # Get the list of stop words using stopwords.words('english')
  review_word=[word for word in review_word if not word in set(stopwords.words('english'))]
  ps=PorterStemmer()
  review1=[ps.stem(word) for word in review_word]
  review2=' '.join(review1)
  corpus.append(review2)

corpus[:1000]

set(stopwords.words('english'))

X = corpus
X[0]

y=df.iloc[:,-1].values

y.shape

from sklearn.model_selection import train_test_split
#Assign the corpus to the variable X
X = corpus
X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=104,test_size=0.2)

!pip install scikit-learn # Install the scikit-learn library
from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB # Correct the typo: 'navie_bayes' to 'naive_bayes'

clf1= GaussianNB()
clf2= MultinomialNB()
clf3= BernoulliNB()

!pip install scikit-learn
import pandas as pd
from nltk.stem.porter import PorterStemmer
import nltk
from nltk.corpus import stopwords
import re
import string
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer  # Import CountVectorizer
from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB

# ... (Your existing code for data preprocessing and corpus creation) ...

# Create a CountVectorizer instance
vectorizer = CountVectorizer()

# Fit the vectorizer to your training data and transform it
X_train_vec = vectorizer.fit_transform(X_train)

# Transform your test data using the same vectorizer
X_test_vec = vectorizer.transform(X_test)

# Now you can fit your classifiers using the vectorized data
clf1 = GaussianNB()
clf2 = MultinomialNB()
clf3 = BernoulliNB()

clf1.fit(X_train_vec.toarray(), y_train)  # Convert to dense array for GaussianNB
clf2.fit(X_train_vec, y_train)
clf3.fit(X_train_vec, y_train)

X[0]

df["Review"]

from sklearn.feature_extraction.text import CountVectorizer

# Create an instance of CountVectorizer
cv = CountVectorizer()

# Now you can use 'cv'
X = cv.fit_transform(corpus).toarray()

X.shape

X[0]

X[0].max()

y=df.iloc[:,-1].values

y.shape

from sklearn.metrics import accuracy_score

# Assuming clf1 is your Gaussian Naive Bayes classifier and X_test_vec is your vectorized test data
y_predG = clf1.predict(X_test_vec.toarray()) # Predict using Gaussian Naive Bayes classifier

# Now you can calculate the accuracy
accuracy_score(y_test, y_predG)

accuracy_score(y_test,y_predG)

# Assuming clf2 is your Multinomial Naive Bayes classifier and X_test_vec is your vectorized test data
y_predM = clf2.predict(X_test_vec)  # Predict using Multinomial Naive Bayes classifier

# Now you can calculate the accuracy
accuracy_score(y_test, y_predM)

y_predB = clf2.predict(X_test_vec)
accuracy_score(y_test, y_predB)

print("Gussian",accuracy_score(y_test, y_predG))
print("Multinomial",accuracy_score(y_test, y_predM))
print("Bernoulli",accuracy_score(y_test, y_predB))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
rf = RandomForestClassifier()
rf.fit(X_train_vec,y_train)
y_pred = rf.predict(X_test_vec)
accuracy_score(y_test,y_pred)

from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(X_train_vec,y_train)
y_pred = xgb.predict(X_test_vec)
accuracy_score(y_test,y_pred)

from sklearn.metrics import confusion_matrix # Import confusion_matrix
from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(X_train_vec,y_train)
y_pred = xgb.predict(X_test_vec)
accuracy_score(y_test,y_pred)

# for xgboost model
confusion_matrix(y_test,y_pred)

#for Gussian model
confusion_matrix(y_test,y_predG)

# for Multinominal model
confusion_matrix(y_test,y_predM)

#FOR Bernoli model
confusion_matrix(y_test,y_predB)

from sklearn.feature_extraction.text import TfidfVectorizer # Import the TfidfVectorizer class

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(corpus)
df = pd.DataFrame(data=X.toarray(),columns=vectorizer.get_feature_names_out())
print(df.tail(30))

